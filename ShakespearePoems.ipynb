{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FJrEbgcOGRF5"
      },
      "outputs": [],
      "source": [
        "# Library imports\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ABueQrkGUDX",
        "outputId": "60f10cb9-0871-4973-d7bb-3adf77db7aff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "EkHZqQkKIU0A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning values unto text\n",
        "characters = sorted(set(text))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
        "\n",
        "SEQ_LENGTH = 40\n",
        "STEP = 3\n",
        "\n",
        "sentences = []\n",
        "next_characters = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_characters.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "jrjxDtfBK4HJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting training data into a numpy array\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "YXQAtBDVLwhx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
        "model.fit(x, y, batch_size=256, epochs=4)\n",
        "model.save('textgenerator.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xocg3XipODep",
        "outputId": "df0567c5-c74a-4e21-cfea-6b3ae0a4f2aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 118s 178ms/step - loss: 2.7158\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 115s 177ms/step - loss: 2.3169\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 117s 179ms/step - loss: 2.2043\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 117s 179ms/step - loss: 2.1283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def generate_text(length, temperature):\n",
        "  start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "  generated_text = ''\n",
        "  sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "  generated_text += sentence\n",
        "  for i in range(length):\n",
        "      x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "      for t, char in enumerate(sentence):\n",
        "          x_pred[0, t, char_to_index[char]] = 1.\n",
        "\n",
        "      predictions = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(predictions, temperature)\n",
        "      next_char = index_to_char[next_index]\n",
        "\n",
        "      generated_text += next_char\n",
        "      sentence = sentence[1:] + next_char\n",
        "\n",
        "  return generated_text\n",
        "\n",
        "\n",
        "print(\"------0.2--------\")\n",
        "print(generate_text(300, 0.2))\n",
        "print(\"------0.6--------\")\n",
        "print(generate_text(300, 0.6))\n",
        "print(\"------0.5--------\")\n",
        "print(generate_text(300, 0.5))\n",
        "print(\"------0.8--------\")\n",
        "print(generate_text(300, 0.8))\n",
        "print(\"------1.0--------\")\n",
        "print(generate_text(300, 1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtluEtzYRPUZ",
        "outputId": "51023857-2fef-48aa-e87f-b34104519ef0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------0.2--------\n",
            "d,\n",
            "i dare your quenchless fury to more roust and hard and the hard and the hare the here the her the the beather in the hard and the hard and and the hard and and and and the hare her here the hard the hare the hare the hand and the hand the her the hing the hand the hare so the the hour the hath the hand the hare the and the hare the her\n",
            "------0.6--------\n",
            ",\n",
            "she came adorned hither like sweet may that to hons wich to the peat thobes then, for, the e the ke the porsto for couns and the pare,\n",
            "i me thil the sartse the farke the well thoun were stay, harce on the king som,\n",
            "and hene ho hear heant thie the ater,\n",
            "shave fores nos couns and we tha his shand chand i whe hard.\n",
            "\n",
            "henme the kay have in t\n",
            "------0.5--------\n",
            "gonus:\n",
            "hang all the husbands\n",
            "that cannot hane the wath the wing the forlly grather, and hear hear lof hear my mens be where ol my king the land the the are in the pared whin the fare,\n",
            "and dow he be the preather ware stoun the here is himerenes mone the gand her and with the here;\n",
            "ar the here in the hall with with the lere sore's and his m\n",
            "------0.8--------\n",
            "ou\n",
            "i do remain as neuter. so, fare you why whis dotheur her bod thy dacr hath ngart the ur hesh.\n",
            "\n",
            "romern:\n",
            "on mery art-ther came whes hande, and an freke gorlif.\n",
            "\n",
            "daren:\n",
            "i in thear, eur to lous ofrers on thalls one hard\n",
            "\n",
            "foydrushs bout me pitound ir bat has dile haty, whan?\n",
            "what nom well and thai sfyroffond herry shourd tath buunl hanwar m\n",
            "------1.0--------\n",
            "ute,--or thought,--for cogitation\n",
            "residend hray the wruid the we'sland\n",
            "and wethald:, alay, you pronl'd searce that is thim and you herom\n",
            "or: raint you nreno;\n",
            "vee that thew s lprixk, acast allofkend to fare?\n",
            "\n",
            "dighe to thir a stithick,\n",
            "\n",
            "tach, be this, io an to; wa,\n",
            "blice eerst hurts?\n",
            "\n",
            "wallich:\n",
            "now thimi:\n",
            "thass ald s ayen\n",
            "whit in you bout on\n"
          ]
        }
      ]
    }
  ]
}